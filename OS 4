To calculate the sum of randomly generated 1000 numbers stored in an array using MPI on a cluster, you can follow these steps:

1. Generate 1000 random numbers on each process in the cluster.
2. Distribute these random numbers among the processes using MPI_Scatter.
3. Each process calculates the sum of its portion of the array.
4. Use MPI_Reduce to gather all the partial sums from each process and compute the total sum.

Here is a basic outline of how the MPI program might look in C:

```c
#include <stdio.h>
#include <stdlib.h>
#include <mpi.h>

#define ARRAY_SIZE 1000

int main(int argc, char *argv[]) {
    int rank, size;
    int array[ARRAY_SIZE];
    int local_sum = 0;
    int total_sum = 0;

    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    // Generate random numbers
    for (int i = 0; i < ARRAY_SIZE; i++) {
        array[i] = rand() % 100; // Generate random numbers between 0 and 99
    }

    // Scatter the array to all processes
    MPI_Scatter(array, ARRAY_SIZE/size, MPI_INT, array, ARRAY_SIZE/size, MPI_INT, 0, MPI_COMM_WORLD);

    // Calculate local sum
    for (int i = 0; i < ARRAY_SIZE/size; i++) {
        local_sum += array[i];
    }

    // Reduce all local sums to get the total sum
    MPI_Reduce(&local_sum, &total_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);

    if (rank == 0) {
        printf("Total sum of 1000 random numbers: %d\n", total_sum);
    }

    MPI_Finalize();

    return 0;
}
```

Remember to compile this program with an MPI compiler (e.g., mpicc) and run it on your cluster using an MPI job scheduler. This program will generate 1000 random numbers, distribute them among processes, calculate the local sum on each process, and then reduce the sums to get the total sum of all numbers.



To find the minimum and maximum numbers from randomly generated 1000 numbers stored in an array using MPI on a cluster, you can utilize MPI_Reduce to gather the minimum and maximum values from all processes. Here's a basic outline of how the MPI program might look in C:

```c
#include <stdio.h>
#include <stdlib.h>
#include <mpi.h>

#define ARRAY_SIZE 1000

int main(int argc, char *argv[]) {
    int rank, size;
    int array[ARRAY_SIZE];
    int local_min = INT_MAX;
    int local_max = INT_MIN;
    int global_min, global_max;

    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    // Generate random numbers
    for (int i = 0; i < ARRAY_SIZE; i++) {
        array[i] = rand() % 100; // Generate random numbers between 0 and 99
    }

    // Scatter the array to all processes
    MPI_Scatter(array, ARRAY_SIZE/size, MPI_INT, array, ARRAY_SIZE/size, MPI_INT, 0, MPI_COMM_WORLD);

    // Find local min and max
    for (int i = 0; i < ARRAY_SIZE/size; i++) {
        if (array[i] < local_min) {
            local_min = array[i];
        }
        if (array[i] > local_max) {
            local_max = array[i];
        }
    }

    // Reduce all local mins to get the global min
    MPI_Reduce(&local_min, &global_min, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);

    // Reduce all local maxs to get the global max
    MPI_Reduce(&local_max, &global_max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);

    if (rank == 0) {
        printf("Minimum number: %d\n", global_min);
        printf("Maximum number: %d\n", global_max);
    }

    MPI_Finalize();

    return 0;
}
```

Compile this program with an MPI compiler (e.g., mpicc) and run it on your cluster using an MPI job scheduler. This program will generate 1000 random numbers, distribute them among processes, find the local minimum and maximum on each process, and then reduce these values to get the global minimum and maximum numbers from
